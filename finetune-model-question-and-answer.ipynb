{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8522192,"sourceType":"datasetVersion","datasetId":5088632},{"sourceId":8522423,"sourceType":"datasetVersion","datasetId":5088807}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\n\ndef read_json(path):\n    with open(path, 'rb') as f:\n        squad_dict = json.load(f)\n\n    # initialize lists for contexts, questions, and answers\n    contexts = []\n    questions = []\n    answers = []\n    # iterate through all data in squad data\n    for group in squad_dict['data']:\n        for passage in group['paragraphs']:\n            context = passage['context']\n            for qa in passage['qas']:\n                question = qa['question']\n                if 'plausible_answers' in qa.keys():\n                    access = 'plausible_answers'\n                else:\n                    access = 'answers'\n                for answer in qa['answers']:\n                    # append data to lists\n                    contexts.append(context)\n                    questions.append(question)\n                    answers.append(answer)\n    # return formatted data lists\n    return contexts, questions, answers\n\n# apply function\ntrain_contexts, train_questions, train_answers = read_json('/kaggle/input/mashqa-dataset/train_webmd_squad_v2_consec.json')\nval_contexts, val_questions, val_answers = read_json('/kaggle/input/mashqa-dataset/val_webmd_squad_v2_consec.json')","metadata":{"execution":{"iopub.status.busy":"2024-05-26T22:55:54.450634Z","iopub.execute_input":"2024-05-26T22:55:54.450940Z","iopub.status.idle":"2024-05-26T22:55:55.937941Z","shell.execute_reply.started":"2024-05-26T22:55:54.450915Z","shell.execute_reply":"2024-05-26T22:55:55.937036Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Tokenize\n\nThe idea is to use a custom dataset, so we need to make sure that it has the same structure as squad from Hugging Face dataset","metadata":{}},{"cell_type":"code","source":"def create_answers_dict(x):\n    dict_ = {\"text\":[(x[\"answer\"])], \"answer_start\":[(int(x[\"answer_start\"]))]}\n    return dict_","metadata":{"execution":{"iopub.status.busy":"2024-05-26T22:55:55.940137Z","iopub.execute_input":"2024-05-26T22:55:55.940784Z","iopub.status.idle":"2024-05-26T22:55:55.946517Z","shell.execute_reply.started":"2024-05-26T22:55:55.940749Z","shell.execute_reply":"2024-05-26T22:55:55.945545Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n#train\ncontexts_df_train = pd.DataFrame(train_contexts, columns=['context'])\nquestions_df_train = pd.DataFrame(train_questions, columns=['question'])\nanswers_df_train = pd.DataFrame.from_records(train_answers)\ndf_train = contexts_df_train.copy()\ndf_train[\"question\"] = questions_df_train[\"question\"]\ndf_train[\"answer\"] = answers_df_train[\"text\"]\ndf_train[\"answer_start\"] = answers_df_train[\"answer_start\"]\ndf_train.reset_index(inplace=True, drop = False)\ndf_train.rename(columns={'index':'id'}, inplace=True)\ndf_train[\"answers\"] = df_train.apply(lambda x: create_answers_dict(x), axis = 1)\n\n#test\ncontexts_df_test = pd.DataFrame(val_contexts, columns=['context'])\nquestions_df_test = pd.DataFrame(val_questions, columns=['question'])\nanswers_df_test = pd.DataFrame.from_records(val_answers)\ndf_test = contexts_df_test.copy()\ndf_test[\"question\"] = questions_df_test[\"question\"]\ndf_test[\"answer\"] = answers_df_test[\"text\"]\ndf_test[\"answer_start\"] = answers_df_test[\"answer_start\"]\ndf_test.reset_index(inplace=True, drop = False)\ndf_test.rename(columns={'index':'id'}, inplace=True)\ndf_test[\"answers\"] =  df_test.apply(lambda x: create_answers_dict(x), axis = 1)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T22:55:55.948040Z","iopub.execute_input":"2024-05-26T22:55:55.948365Z","iopub.status.idle":"2024-05-26T22:55:57.413778Z","shell.execute_reply.started":"2024-05-26T22:55:55.948337Z","shell.execute_reply":"2024-05-26T22:55:57.412897Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   id                                            context  \\\n0   0  If it's temporary and only happens occasionall...   \n1   1  If it's temporary and only happens occasionall...   \n2   2  If it's temporary and only happens occasionall...   \n3   3  If it's temporary and only happens occasionall...   \n4   4  Prostate cancer is not often a cause of erecti...   \n\n                                            question  \\\n0  What are some conditions that can lead to erec...   \n1  If I see a urologist for erectile dysfunction,...   \n2  What if I'm concerned about talking to my doct...   \n3  What questions might my doctor ask about my er...   \n4  What is the link between prostate cancer and e...   \n\n                                              answer  answer_start  \\\n0  Other options your doctor can help you explore...           714   \n1  The urologist will ask what happens when you h...          3816   \n2  The best approach is just to say, \" I think I ...          2565   \n3  The questions may include: Do you ever get an ...          3071   \n4  However, treatments for the disease can cause ...            70   \n\n                                             answers  \n0  {'text': ['Other options your doctor can help ...  \n1  {'text': ['The urologist will ask what happens...  \n2  {'text': ['The best approach is just to say, \"...  \n3  {'text': ['The questions may include: Do you e...  \n4  {'text': ['However, treatments for the disease...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>answer_start</th>\n      <th>answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>If it's temporary and only happens occasionall...</td>\n      <td>What are some conditions that can lead to erec...</td>\n      <td>Other options your doctor can help you explore...</td>\n      <td>714</td>\n      <td>{'text': ['Other options your doctor can help ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>If it's temporary and only happens occasionall...</td>\n      <td>If I see a urologist for erectile dysfunction,...</td>\n      <td>The urologist will ask what happens when you h...</td>\n      <td>3816</td>\n      <td>{'text': ['The urologist will ask what happens...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>If it's temporary and only happens occasionall...</td>\n      <td>What if I'm concerned about talking to my doct...</td>\n      <td>The best approach is just to say, \" I think I ...</td>\n      <td>2565</td>\n      <td>{'text': ['The best approach is just to say, \"...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>If it's temporary and only happens occasionall...</td>\n      <td>What questions might my doctor ask about my er...</td>\n      <td>The questions may include: Do you ever get an ...</td>\n      <td>3071</td>\n      <td>{'text': ['The questions may include: Do you e...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Prostate cancer is not often a cause of erecti...</td>\n      <td>What is the link between prostate cancer and e...</td>\n      <td>However, treatments for the disease can cause ...</td>\n      <td>70</td>\n      <td>{'text': ['However, treatments for the disease...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Saving dataframes to .csv","metadata":{}},{"cell_type":"code","source":"\ndf_train.sample(frac = 0.5)[['id', 'context', 'question', 'answers']].to_csv('/kaggle/working/dataset_train.csv', index=False)\ndf_test.sample(frac = 0.5)[['id', 'context', 'question', 'answers']].to_csv('/kaggle/working/dataset_test.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T22:55:57.416271Z","iopub.execute_input":"2024-05-26T22:55:57.416677Z","iopub.status.idle":"2024-05-26T22:56:00.286754Z","shell.execute_reply.started":"2024-05-26T22:55:57.416651Z","shell.execute_reply":"2024-05-26T22:56:00.285985Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndata_files = {\"train\": \"/kaggle/working/dataset_train.csv\", \"test\": \"/kaggle/working/dataset_test.csv\"}\nds = load_dataset(\"csv\", data_files=data_files)\nds","metadata":{"execution":{"iopub.status.busy":"2024-05-26T22:56:00.287754Z","iopub.execute_input":"2024-05-26T22:56:00.288004Z","iopub.status.idle":"2024-05-26T22:56:02.802980Z","shell.execute_reply.started":"2024-05-26T22:56:00.287983Z","shell.execute_reply":"2024-05-26T22:56:02.802091Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1ae01da7fa64198a0908355f081584c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2e67a014f7c47e28bb0193d14dcd96e"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'context', 'question', 'answers'],\n        num_rows: 9994\n    })\n    test: Dataset({\n        features: ['id', 'context', 'question', 'answers'],\n        num_rows: 1343\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"The column \"answers\" wasn't saved as a dict (python data structure), it's a string. We nee to change from that string containing the dict to a real dict","metadata":{}},{"cell_type":"code","source":"def convert_text(batch):\n  aux_list = []\n  for x, y in zip(batch[\"answers\"], batch[\"answers\"]):\n    my_dict = {\"text\":eval(x)[\"text\"], \"answer_start\":eval(x)[\"answer_start\"]}\n    aux_list.append(my_dict)\n\n  return {\"texts\":aux_list}\n\nprepared_ds = ds.map(convert_text, batched = True)\nprepared_ds = prepared_ds.remove_columns(\"answers\")\nprepared_ds = prepared_ds.rename_column(\"texts\", \"answers\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T22:56:02.804239Z","iopub.execute_input":"2024-05-26T22:56:02.805108Z","iopub.status.idle":"2024-05-26T22:56:03.541296Z","shell.execute_reply.started":"2024-05-26T22:56:02.805069Z","shell.execute_reply":"2024-05-26T22:56:03.540562Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9994 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2b5f11b66ac466582cff3fe565482d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1343 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2919d243d7ea4927bb882e2ed75fec45"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ndef preprocess_function(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=384,\n        truncation=\"only_second\",\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    print(offset_mapping)\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        answer = answers[i]\n        start_char = answer[\"answer_start\"][0]\n        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find the start and end of the context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label it (0, 0)\n        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-26T22:56:03.542342Z","iopub.execute_input":"2024-05-26T22:56:03.542620Z","iopub.status.idle":"2024-05-26T22:56:11.868920Z","shell.execute_reply.started":"2024-05-26T22:56:03.542597Z","shell.execute_reply":"2024-05-26T22:56:11.868066Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"808d5176b54849e4ac4e88c6bbfd428f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ed1b3e22e941b1bfecbcea45d33cb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0511ead6dc5c4a69a61e3a61e63b552b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f33944a1c3a74ef28054055dbd220f68"}},"metadata":{}}]},{"cell_type":"code","source":"import sys\nimport io\nfrom contextlib import redirect_stdout\n\ndef quiet_map(dataset, function, **kwargs):\n    # Create a string buffer\n    buffer = io.StringIO()\n\n    # Redirect the standard output to the buffer\n    with redirect_stdout(buffer):\n        # Call the map function\n        result = dataset.map(function, **kwargs)\n\n    # Return the result\n    return result\n\n# Now you can call the quiet_map function instead of the map function\ntokenized_squad = quiet_map(prepared_ds, preprocess_function, batched=True, remove_columns=ds[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T22:56:11.869993Z","iopub.execute_input":"2024-05-26T22:56:11.870403Z","iopub.status.idle":"2024-05-26T22:56:37.246590Z","shell.execute_reply.started":"2024-05-26T22:56:11.870381Z","shell.execute_reply":"2024-05-26T22:56:37.245431Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9994 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"533f12fdaa904e6dbe8689b159dc40b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1343 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c45aafc3b7904ba1a684c80737c8ae73"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Login to Hugging Face","metadata":{}},{"cell_type":"code","source":"from dotenv import load_dotenv\nfrom huggingface_hub import login\n\nHUGGING_FACE_API_KEY = ''\nlogin(token = HUGGING_FACE_API_KEY)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T22:56:37.248006Z","iopub.execute_input":"2024-05-26T22:56:37.248685Z","iopub.status.idle":"2024-05-26T22:56:37.481678Z","shell.execute_reply.started":"2024-05-26T22:56:37.248649Z","shell.execute_reply":"2024-05-26T22:56:37.480748Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training\nDefine training arguments and trainer","metadata":{}},{"cell_type":"code","source":"from transformers import DefaultDataCollator, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n\ndata_collator = DefaultDataCollator()\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n\ntraining_args = TrainingArguments(\n    output_dir=\"distilbert-qa\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=4,\n    weight_decay=0.01,\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_squad[\"train\"],\n    eval_dataset=tokenized_squad[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T23:12:46.808461Z","iopub.execute_input":"2024-05-26T23:12:46.809162Z","iopub.status.idle":"2024-05-26T23:27:15.335763Z","shell.execute_reply.started":"2024-05-26T23:12:46.809131Z","shell.execute_reply":"2024-05-26T23:27:15.334731Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2500/2500 14:20, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.928800</td>\n      <td>1.466246</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.478700</td>\n      <td>1.341967</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.327200</td>\n      <td>1.326671</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.113300</td>\n      <td>1.372438</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2500, training_loss=1.4100805908203125, metrics={'train_runtime': 860.7079, 'train_samples_per_second': 46.445, 'train_steps_per_second': 2.905, 'total_flos': 3917241245159424.0, 'train_loss': 1.4100805908203125, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model()\nmetrics = trainer.evaluate(tokenized_squad[\"test\"])\n\nkwargs = {\n    \"finetuned_from\": model.config._name_or_path,\n    \"tasks\": \"question-answering\",\n    \"dataset\": \"mashqa_dataset\",\n    \"tags\":[\"question-answering\", \"nlp\"]\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-26T23:27:45.225012Z","iopub.execute_input":"2024-05-26T23:27:45.225872Z","iopub.status.idle":"2024-05-26T23:28:00.295358Z","shell.execute_reply.started":"2024-05-26T23:27:45.225840Z","shell.execute_reply":"2024-05-26T23:28:00.294350Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1716765168.e0cf7a6de512.34.2:   0%|          | 0.00/6.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1de565ddc474d28b980b91027fc07df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [84/84 00:09]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message = \"model tuned\", **kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T23:28:05.536314Z","iopub.execute_input":"2024-05-26T23:28:05.537114Z","iopub.status.idle":"2024-05-26T23:28:10.819368Z","shell.execute_reply.started":"2024-05-26T23:28:05.537082Z","shell.execute_reply":"2024-05-26T23:28:10.818117Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1716766080.e0cf7a6de512.34.3:   0%|          | 0.00/359 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"869de0e8c8674a58b3ad0b7d2f29fe59"}},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Eurosmart/distilbert-qa/commit/449449d38d6e324d9bfd63ae7a2ab15535052a42', commit_message='model tuned', commit_description='', oid='449449d38d6e324d9bfd63ae7a2ab15535052a42', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}